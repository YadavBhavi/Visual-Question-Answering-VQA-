# Visual-Question-Answering-VQA-
Course Project, Guide: Prof Pushpak Bhattacharya; [April ’23]

Developed a NLP-VQA model, capable of giving natural language answers to questions related to images \n
• Achieved commendable 50% accuracy(25) as compared to humans(50) on DAQUAR (NYU) dataset \n
• Analyzed diverse set of text encoders–BERT, RoBERTa, ALBERT, image encoders–ViT,DeiT,BeiT
