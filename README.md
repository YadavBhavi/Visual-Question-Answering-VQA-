# Visual-Question-Answering-VQA-
Course Project, Guide: Prof Pushpak Bhattacharya; [April ’23] <br />

-> Developed a NLP-VQA model, capable of giving natural language answers to questions related to images <br />
-> Achieved commendable 50% accuracy(25) as compared to humans(50) on DAQUAR (NYU) dataset <br />
-> Analyzed diverse set of text encoders–BERT, RoBERTa, ALBERT, image encoders–ViT,DeiT,BeiT <br />

Click [here](./presentation_vqa.pdf) for more details <br />

Papaer implemented -> [VQA: Visual Question Answering, Agrawal, Lu et.al] (https://arxiv.org/pdf/1505.00468.pdf)
